
import warnings
import joblib
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd

from evaluate import evaluate_model

from sklearn.calibration import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
                      
from xgboost import XGBClassifier


df = pd.read_csv("data/ransom_vs_malware.csv")

#same function as preprocess - modified for this dataset
def preprocess(df):

     # ----- Turn Target to Ransomware vs Non-Ransomware
    # normalize everything to lower case before transforming
    vals = df['Malware_Type'].astype(str).str.lower()

    #match anything containing the keyword ransom
    is_ransomware = vals.str.contains('ransom', na=False)

    #new column - numeric labels 1/0
    df['Ransomware'] = is_ransomware.astype(int)

    #drop original target column
    df = df.drop(columns=['Malware_Type'])

    categorical_cols = [
        'Machine', 'Subsystem', 'Magic',
        'SizeOfOptionalHeader', 'LoaderFlags', 'NumberOfRvaAndSizes'
    ]
    
    #label encoding - replaces each category with an integer code(ok for tree)
    for col in categorical_cols:
        df[col] = df[col].astype('category').cat.codes
    
    # --- Drop Identifiers ---
    meta = df[['SHA256']].copy()
    df = df.drop(columns=['SHA256'])


    # drop highly correlated numeric columns only (needed for SVM)
    corr = df.select_dtypes(include=[np.number]).drop(columns=['Ransomware'], errors='ignore').corr().abs()
    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))
    drop_cols = [c for c in upper.columns if any(upper[c] > 0.95)]
    df.drop(columns=drop_cols, inplace=True)

    #Mostly needed for linear models - so larger values dont dominate smaller ones
    log_cols = [
        'SizeOfImage', 'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData',
        'AddressOfEntryPoint', 'ImageBase', 'BaseOfCode', 'FileAlignment',
        'SectionAlignment', 'SizeOfStackReserve', 'SizeOfHeapReserve',
        'SizeOfHeapCommit', 'SizeOfHeaders', 'PointerToSymbolTable',
        'NumberOfSymbols', 'CheckSum', 'SizeOfOptionalHeader', 'TimeDateStamp'
    ]
    for col in log_cols:
        if col in df.columns:
            df[col] = np.log1p(df[col])

    # Split Features vs Target
    X = df.drop(columns=['Ransomware'])
    y = df['Ransomware']

    return X, y, meta



X, y, meta = preprocess(df)



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

#handling unbalanced data
#sm = SMOTE(random_state=42)
#X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)


# ---- Random Forest ----


# best parameters found using randomSearch (see ipynb)
rf = RandomForestClassifier(n_estimators=753, 
                            max_depth=24,
                            min_samples_leaf=3,
                            min_samples_split=3,
                            class_weight="balanced",
                            random_state=42)


rf.fit(X_train, y_train)



# ---- XGBoost ----


xgb = XGBClassifier(
    n_estimators=200,
    learning_rate=0.03,
    scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train),  # balance weight
    max_depth=3,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'  # suppresses warning
)
# Train and evaluate
xgb.fit(X_train, y_train)


#------ SVM -------

#best parameters found in ipynb
final_svm = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", LinearSVC(
        C=0.001,
        dual=False,
        max_iter=20000,
        tol=1e-3,
        class_weight="balanced"
    ))
])

final_svm.fit(X_train, y_train)

final_svm.predict(X_test)


print("\n--- Evaluation using AUC ---")

# Random Forest
evaluate_model(rf, X_test, y_test, model_name="Random Forest")

# XGBoost
evaluate_model(xgb, X_test, y_test, model_name="XGBoost")

# SVM 
evaluate_model(final_svm, X_test, y_test, model_name="SVM")

# --- for the CLI -----

#save best performing model
joblib.dump(xgb, "models/ransom_vs_malware.pkl")

#save train dataset
X_train.to_csv("data/X_ransom_vs_malware.csv", index=False)

#save labels - having to name everything is getting out of control
y_train.to_csv("data/labels_ransom_vs_malware", index=False)
